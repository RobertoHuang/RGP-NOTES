# `Kafka`安装与部署

>  关于我:[http://huangth.com](http://huangth.com)
>
>  GitHub地址:[https://github.com/RobertoHuang](https://github.com/RobertoHuang)

在上一篇博客中介绍了[Kafka单机版的安装与部署](https://github.com/RobertoHuang/RGP-NOTES/blob/master/Kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/01.kafka%E5%8D%95%E6%9C%BA%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%B5%8B%E8%AF%95.md)，本博客将介绍`Kafka`集群版的安装与部署

单个`Kafka`服务器足以满足本地开发或`POC`要求，不过集群也有它的强大之处。使用集群最大的好处是可以跨服务器进行负载均衡，再则就是可以使用复制功能来避免因单点故障造成的数据丢失，因此在维护`Kafka`或底层系统时使用集群可以确保为客户端提供高可用性。【由于物理机有限本博客搭建的是伪集群】

- [Zookeeper集群环境搭建](https://github.com/RobertoHuang/RGP-NOTES/tree/master/Zookeeper%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0)

- 创建`kafka`数据文件目录

  ```shell
  # mkdir -p /opt/kafka/kafka-logs/node1
  # mkdir -p /opt/kafka/kafka-logs/node2
  # mkdir -p /opt/kafka/kafka-logs/node3
  ```

- 修改`Kafka`配置文件`server.properties`

  ```shell
  # 进入kafka配置文件目录
  # cd /opt/kafka/kafka_2.10-0.10.2.1/config
  
  # 拷贝三份server.properties配置
  # cp server.properties server_node1.properties
  # cp server.properties server_node2.properties
  # cp server.properties server_node3.properties
  
  # 分别修改三个节点的配置文件
  # vim server_node1.properties
  
  # 修改配置文件内容如下
  
  # 这是这台虚拟机上的值 在另外两个节点上应该是2或者3
  # 这个值是唯一的，每台虚拟机或者叫服务器不能相同
  broker.id=1
  # kafka服务监听端口 其他两个节点分别为9093 9094
  listeners=PLAINTEXT://192.168.56.128:9092
  # 数据文件目录 其他两个节点分别为node2 node3
  log.dirs=/opt/kafka/kafka-logs/node1
  # 在og.retention.hours=168下面新增下面三项
  message.max.byte=5242880
  default.replication.factor=2
  replica.fetch.max.bytes=5242880
  # 设置zookeeper的连接端口
  zookeeper.connect=192.168.56.128:2181,192.168.56.128:2182,192.168.56.128:2183
  ```

- 修改日志打印

  - 修改日志配置文件

    ```shell
    # 进入配置文件目录
    # cd opt/kafka/kafka_2.10-0.10.2.1/config
    
    # 拷贝三份log4j.properties配置
    # cp log4j.properties log4j_node1.properties
    # cp log4j.properties log4j_node2.properties
    # cp log4j.properties log4j_node3.properties
    
    # 分别修改三个节点的配置文件
    # vim log4j_node1.properties
    
    # 修改配置文件内容如下 在日志文件后加上对应的节点用于区分
    log4j.appender.kafkaAppender.File=${kafka.logs.dir}/server-node1.log
    log4j.appender.stateChangeAppender.File=${kafka.logs.dir}/state-change-node1.log
    log4j.appender.requestAppender.File=${kafka.logs.dir}/kafka-request-node1.log
    log4j.appender.cleanerAppender.File=${kafka.logs.dir}/log-cleaner-node1.log
    log4j.appender.controllerAppender.File=${kafka.logs.dir}/controller-node1.log
    log4j.appender.authorizerAppender.File=${kafka.logs.dir}/kafka-authorizer-node1.log
    ```

  - 修改启动脚本配置

    ```shell
    # 进入启动脚本目录
    # cd /opt/kafka/kafka_2.10-0.10.2.1/bin
    
    # 拷贝三份启动脚本
    # cp kafka-server-start.sh kafka-server-start-node1.sh
    # cp kafka-server-start.sh kafka-server-start-node2.sh
    # cp kafka-server-start.sh kafka-server-start-node3.sh
    
    # 分别修改三个节点的启动脚本
    # vim kafka-server-start-node1.sh
    
    # 修改配置文件内容如下 将日志配置指向对应节点的log4j配置
    export KAFKA_LOG4J_OPTS="-Dlog4j.configuration=file:$base_dir/../config/log4j_node1.properties"
    ```

- 启动`kafka`集群

  ```shell
  # /opt/kafka/kafka_2.10-0.10.2.1/bin/kafka-server-start-node1.sh -daemon /opt/kafka/kafka_2.10-0.10.2.1/config/server_node1.properties
  # /opt/kafka/kafka_2.10-0.10.2.1/bin/kafka-server-start-node2.sh -daemon /opt/kafka/kafka_2.10-0.10.2.1/config/server_node2.properties
  # /opt/kafka/kafka_2.10-0.10.2.1/bin/kafka-server-start-node3.sh -daemon /opt/kafka/kafka_2.10-0.10.2.1/config/server_node3.properties
  ```

- 检查服务是否已启动

  ```shell
  # jps
  1344 QuorumPeerMain
  2516 Jps
  1318 QuorumPeerMain
  2189 Kafka
  2461 Kafka
  1918 Kafka
  1295 QuorumPeerMain
  ```

- 测试`kafka`服务

  - 创建并验证主题

    ```shell
    # 创建Topic
    # /opt/kafka/kafka_2.10-0.10.2.1/bin/kafka-topics.sh --create --zookeeper 192.168.56.128:2181 --replication-factor 2 --partitions 1 --topic test
    
    # 验证Topic
    # /opt/kafka/kafka_2.10-0.10.2.1/bin/kafka-topics.sh --zookeeper 192.168.56.128:2181 --describe --topic test
    
    Topic:test      PartitionCount:1        ReplicationFactor:2     Configs:
    Topic: test     Partition: 0    Leader: 1       Replicas: 1,2   Isr: 1,2
    ```

  - 往`test`主题上发布消息

    ```shell
    #`这个IP地址可以写brokerlist中的任意一个
    # /opt/kafka/kafka_2.10-0.10.2.1/bin/kafka-console-producer.sh --broker-list 192.168.56.128:9092 --topic test
    ```

  - 接收`test`主题上发布的消息

    ```shell
    # /opt/kafka/kafka_2.10-0.10.2.1/bin/kafka-console-consumer.sh --zookeeper 192.168.56.128:2181 --topic test --from-beginning
    ```