# `Kafka`消费者

## `Consumer`示例

- 导入依赖

  ```xml
  <dependency>
      <groupId>org.apache.kafka</groupId>
      <artifactId>kafka-clients</artifactId>
      <version>0.10.1.0</version>
  </dependency>
  ```

- `Consumer`最简单的应用示例

  ```java
  public class KafkaConsumerTest {
      public static void main(String[] args) throws InterruptedException {
          Properties properties = new Properties();
          properties.put("bootstrap.servers", "192.168.56.128:9092,192.168.56.128:9093,192.168.56.128:9094");
          properties.put("group.id", "testGroup");
          properties.put("auto.offset.reset", "earliest");
          properties.put("enable.auto.commit", "true");
          properties.put("auto.commit.interval.ms", "1000");
          properties.put("session.timeout.ms", "30000");
          properties.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
          properties.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
          KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
          consumer.subscribe(Arrays.asList("test"));
          try {
              while (true) {
                  ConsumerRecords<String, String> records = consumer.poll(0);
                  for (ConsumerRecord<String, String> record : records) {
                      System.out.printf("offset = %d, key = %s, value = %s \n", record.offset(), record.key(), record.value());
                  }
                  Thread.sleep(10000);
              }
          } finally {
              consumer.close();
          }
      }
  }
  ```

## `HeartbeatThread`

消费者需要定时的向服务端的协调者发送心跳以表明自己是存活的，如果消费者在一段时间内没有发送心跳到服务端的协调者，那么服务端的协调者就会认为消费者挂掉，就会将挂掉的消费者上的分区分给消费组中的其他消费者

【`poll->ensureActiveGroup()->startHeartbeatThreadIfNeeded()->HeartbeatThread().start()`】

- `heartbeat.sessionTimeoutExpired`在会话超时时间内没有收到心跳应答，客户端认为协调者挂了
- `heartbeat.pollTimeoutExpired`查看消费者客户端的轮询时不是超过了心跳最大的轮询等待时间
- `HeartbeatResponseHandler`处理心跳请求结果 -> 【根据`HeartbeatResponse`做相应处理】

## `PartitionAssignor`

消费者组里的`Leader`在收到`JoinGroupResponse`之后会按照其中指定的分区分配策略进行分区分配，每一个分区分配策略就是一个`PartitionAssignor`接口的实现。【分区分配策略】进行分区分配需要两方面的数据

- `Subscription`

  `Metadata`中记录的集群元数据和每一个消费者成员的订阅信息，为了增强用户对分配结果的控制就将用户订阅信息和一些影响分配的用户自定义信息封装成`Subscription`【`subscription()`用于添加自定义数据】

- `Assignment`

  保存分区分配结果:`partitions`:分配给某消费者的`TopicPartition`集合 `userData`:用户自定义数据

## `SubscriptionState`

从`Kafka`拉取消息时发送的请求时`FetchRequest`，在其中需要指定消费者希望拉取的起始消息的`offset`。为了消费者快速获取这个值使用`SubscriptionState`来追踪`TopicPartition`与`offset`的关系

- `subscribe()`
  - 设置`AUTO_TOPICS`订阅类型 初始化监听器
  - 检测监听的`topic`是否发生变化，如果发生变化重置
- `subscribeFromPattern()`
  - 设置`AUTO_TOPICS`订阅类型
  - 检测监听的`topic`是否发生变化，如果发生变化重置
- `TopicPartitionState`表示`TopicPartition`的消费状态

## `ConsumerNetworkClient`

`ConsumerNetworkClient`是对`NetworkClient`的一个封装提供了额外的一些功能

- `poll()`实现发送请求的功能
  - 触发`pendingCompleted`里的请求
  - 循环处理`unsent`中缓存的请求，将符合条件的请求放入`KafkaChannel`的`send`字段中等待发送
  - 检测我们是否需要立即调用`NetworkClient.poll`
  - 检测消费者与`Node`连接状态，当检测到连接断开时会将其在`unsent`列表对应的全部`ClientRequest`对象清除掉，之后调用这些`ClientRequest`回调函数并且设置`disconnect`标记为`true`
  - 检测`wakeup`和`wakeupDisabledCount`查看是否有其他线程中断，如果可中断则抛出异常
  - 再次试图发送，可能现在内存已经清理了或者`Node`可以连接上了
  - 处理`unsent`中的超时请求，它会遍历整个`unsent`集合检测每一个`ClientRequest`是否超时，调用超时`ClientRequest`的回调函数并将其从`unsent`列表删除
- `poll(RequestFuture<?> future)`实现阻塞发送请求的功能
- `send()`将待发送的请求封装成`ClientRequest`保存到`unsent`集合中等待发送

## `ConsumerCoordinator`

- `Rebalance`相关
  - `invokeCompletedOffsetCommitCallbacks`调用`offset`提交请求的回调函数

  - `ensureCoordinatorReady`判断对于这个组的`coordinatior`是否已经准备好接受请求，否则一直阻塞

  - 判断是否需要发送`JoinGroupRequest`请求及是否需要更新`Metadata`

  - 发送`JoinGroupRequest`请求
    - `onJoinPrepare`【准备阶段】
      - 是否需要同步`offset`操作
      - 调用`ConsumerRebalanceListener`
    - `initiateJoinGroup`【初始化+处理阶段】
      - 发送`JoinGroupRequest`请求
      - 解析`JoinGroupResponse`响应，根据是否是`Leader`做不同处理
    - `onJoinComplete`【完成阶段】
      - 更新`SubscriptionState`
      - 调用`ConsumerRebalanceListener`

  状态【`Empty –> PreparingRebalance –> AwaiSync –> Stable`】

- `offset`相关

  - `fetchCommittedOffsets`拉取`offset`信息
  - `commitOffsetsAsync/commitOffsetsSync`提交`offset`信息