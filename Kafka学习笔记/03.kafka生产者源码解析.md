# `Kafka`生产者

## `Producer`使用

- 导入依赖

  ```xml
  <dependency>
      <groupId>org.apache.kafka</groupId>
      <artifactId>kafka-clients</artifactId>
      <version>0.10.1.0</version>
  </dependency>
  ```

- `Producer`最简单的应用示例

  ```java
  public class KafkaProducerTest {
      public static void main(String[] args) {
          Properties properties = new Properties();
          properties.put("bootstrap.server s", "192.168.56.128:9092,192.168.56.128:9093,192.168.56.128:9094");
          properties.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
          properties.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
  
          Producer<String, String> producer = null;
          try {
              producer = new KafkaProducer(properties);
              for (int i = 0; i < 100; i++) {
                  String msg = "Message " + i;
                  producer.send(new ProducerRecord<>("test", "", msg));
              }
          } catch (Exception e) {
              e.printStackTrace();
          } finally {
              producer.close();
          }
      }
  }
  ```


## `Producer`发送流程

- 获取`kafka`集群元数据 确认数据要发送到的`topic`的`metadata`是可用的
- `Serializer`对消息的`key`和`value`进行序列化
- `Partitioner`为消息选择合适的`Partition`
- `RecordAccumulator`收集消息实现消息批量发送
- 如果追加完数据后对应的`RecordBatch`已经达到了`batch.size`的大小(`batch`的剩余空间不足以添加下一条`Record`)或者等待时间到达`lingerMs`则唤醒 `sender` 线程发送数据

## `Metadata`更新机制

- `Metadata`内容是什么

  在`KafkaProducer`中使用`Node`、`TopicPartition`、`PartitionInfo`封装集群相关元数据

  - `Node`代表集群中一个节点
  - `TopicPartition`表示某个`Topic`的一个分区
  - `PartitionInfo`表示一个分区的详细信息

  通过这三个类的组合可以完整表示出`KafkaProducer`需要的集群元数据，这些数据保存在`Cluster`中并按照不同的映射方式进行存放方便查询，`Metadata`中封装了`Cluster`对象并保存与`cluster`操作相关的信息

- `Metadata`的更新流程

  - `waitOnMetadata()`
    - `requestUpdate()`标记需要更新并返回当前元数据版本号
    - `sender.wakeup()`唤醒`Sender`线程->唤醒`NetworkClient`线程
    - `awaitUpdate()`阻塞等待`Metadata`的更新 (主线程与`Sender`线程通过`wait/notifiy`同步)
  - `Sender`线程调用`NetworkClient.poll()`



## `NetworkClient`分析

- 

## `Sender`线程模型分析

- 调用`RecordAccumulator.ready()`选出可以向哪些`Node`节点发送消息，返回`ReadyCheckResult`对象
- 如果`ReadyCheckResult`中标识有`unknownLeaderTopics`则调用`requestUpdate`标记需要更新集群元数据
- 检查`ReadyCheckResult`中`readyNodes`集合网络I/O方面是否符合发送消息的条件，不符合条件的则先移除
- 返回`node`对应的所有可以发送的`RecordBatch`组成的`batches`，`key`为`node.id`
- 处理`RecordAccumulator`中超时的消息【遍历调用`RecordBatch.maybeExpire`】
- 将待发送的消息封装成`ClientRequest`【每个`Node`节点对应一个`ClientRequest`】
- 将消息封装成`ClientRequest`写入`KafkaChannel`的`send`字段等待发送【添加`inFlightRequests`缓存】


## `RecordBatch`

- `ProduceRequestResult`完成生产者请求的一个结果类，但是该类并没有根据并发库下的`Future`来实现而是根据`CountDownLatch`来实现。当`RecordBatch`中全部消息被正常响应/超时/关闭生产者时会调用`done`方法标记完成，可以通过`error`字段区分是异常完成还是正常完成
- `Thunk`是对回调函数`Callback`和其相关参数`FutureRecordMetadata`的一个封装(用于发送回调)
  - `Callback`消息发送回调处理
  - `FutureRecordMetadata`有两个关键字段
    - `result`指向对应消息所在`RecordBatch`的`produceFuture`
    - `relativeOffset`记录了对应消息在`RecordBatch`中的偏移量
- `tryAppend`添加`record`到当前结果集并返回`FutureRecord`元数据对象
- `done`回调`RecordBatch`中全部消息的`callback`回调函数并且调用`ProducerRequestResult.done()`
- `maybeExpire `判断`RecordBatch`处理是否已超时

## `RecordAccumulator`

`RecordAccumulator`中有一个`key`为`TopicPartition` `value`为`Deque<RecordBatch>`的`ConcurrentMap`，每个`RecordBatch`拥有一个`MemoryRecords`对象的引用，`MemoryRecords`表示多个消息的集合

- 添加数据
  - 获取该分区对应的`queue`，没有的话会创建一个空的`queue`
  - 向`queue`中追加数据【先获取`queue`中最新加入的那个`RecordBatch`，如果不存在或者存在但剩余空余不足以添加本条`record`则返回`null`，成功写入的话直接返回结果
  - 创建一个新的`RecordBatch`，初始化内存大小根据`max(batch.size, Records.LOG_OVERHEAD + Record.recordSize(key, value))` 来确定(防止单条`record`过大的情况)
  - 向新建的`RecordBatch` 写入`record`，并将`RecordBatch` 添加到`queue`中，返回结果写入成功
- 获取符合发送消息条件的节点集合
  - `Deque`中有多个`RecordBatch`或是第一个`RecordBatch`是否满了
  - `RecordBatch`没有满但是已经等了`lingerMs`长的时间【到达退避时间】
  - 是否有其他线程在等待`BufferPool`释放空间【`accumulator`满了 】
  - `Sender`线程准备关闭/是否有线程正在等待`flush`操作完成
- 映射转换 `TopicPartition -> RecordBatch` => `NodeId -> RecordBatch`
  - `RecordBatch`对应的`TopicPartition`没有数据在飞【已发送但未收到`ACK`】
  - `RecordBatch`处在`retry`状态并且已经等待了`backoff`长的时间

- 保证`TopicPartition`发送消息顺序

  在`RecordAccumulator`中有`private final Set<TopicPartition> muted;`用来保存已经发送`batch`到`server`中但是没有收到`ACK`的`TopicPartition`【俗称`inflight`】，等到接收到`server`的`reponse`后会将对应的`TopicPartition`从`set`中去掉，这样子就可以保证每个`TopicPartition`的发送顺序

`RecordAccumulator`中使用`BufferPool`来管理内存分配(后续再研究)